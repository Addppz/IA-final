{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisis exploratorio de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1787</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>19</td>\n",
       "      <td>oct</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>4789</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>11</td>\n",
       "      <td>may</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>339</td>\n",
       "      <td>4</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1350</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>16</td>\n",
       "      <td>apr</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1476</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>jun</td>\n",
       "      <td>199</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital  education default  balance housing loan  \\\n",
       "0   30   unemployed  married    primary      no     1787      no   no   \n",
       "1   33     services  married  secondary      no     4789     yes  yes   \n",
       "2   35   management   single   tertiary      no     1350     yes   no   \n",
       "3   30   management  married   tertiary      no     1476     yes  yes   \n",
       "4   59  blue-collar  married  secondary      no        0     yes   no   \n",
       "\n",
       "    contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  cellular   19   oct        79         1     -1         0  unknown  no  \n",
       "1  cellular   11   may       220         1    339         4  failure  no  \n",
       "2  cellular   16   apr       185         1    330         1  failure  no  \n",
       "3   unknown    3   jun       199         4     -1         0  unknown  no  \n",
       "4   unknown    5   may       226         1     -1         0  unknown  no  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información general:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4521 entries, 0 to 4520\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        4521 non-null   int64 \n",
      " 1   job        4521 non-null   object\n",
      " 2   marital    4521 non-null   object\n",
      " 3   education  4521 non-null   object\n",
      " 4   default    4521 non-null   object\n",
      " 5   balance    4521 non-null   int64 \n",
      " 6   housing    4521 non-null   object\n",
      " 7   loan       4521 non-null   object\n",
      " 8   contact    4521 non-null   object\n",
      " 9   day        4521 non-null   int64 \n",
      " 10  month      4521 non-null   object\n",
      " 11  duration   4521 non-null   int64 \n",
      " 12  campaign   4521 non-null   int64 \n",
      " 13  pdays      4521 non-null   int64 \n",
      " 14  previous   4521 non-null   int64 \n",
      " 15  poutcome   4521 non-null   object\n",
      " 16  y          4521 non-null   object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 600.6+ KB\n",
      "\n",
      "Estadísticas descriptivas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4521.000000</td>\n",
       "      <td>4521.000000</td>\n",
       "      <td>4521.000000</td>\n",
       "      <td>4521.000000</td>\n",
       "      <td>4521.000000</td>\n",
       "      <td>4521.000000</td>\n",
       "      <td>4521.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41.170095</td>\n",
       "      <td>1422.657819</td>\n",
       "      <td>15.915284</td>\n",
       "      <td>263.961292</td>\n",
       "      <td>2.793630</td>\n",
       "      <td>39.766645</td>\n",
       "      <td>0.542579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.576211</td>\n",
       "      <td>3009.638142</td>\n",
       "      <td>8.247667</td>\n",
       "      <td>259.856633</td>\n",
       "      <td>3.109807</td>\n",
       "      <td>100.121124</td>\n",
       "      <td>1.693562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>-3313.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>444.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>1480.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>329.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>87.000000</td>\n",
       "      <td>71188.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>3025.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age       balance          day     duration     campaign  \\\n",
       "count  4521.000000   4521.000000  4521.000000  4521.000000  4521.000000   \n",
       "mean     41.170095   1422.657819    15.915284   263.961292     2.793630   \n",
       "std      10.576211   3009.638142     8.247667   259.856633     3.109807   \n",
       "min      19.000000  -3313.000000     1.000000     4.000000     1.000000   \n",
       "25%      33.000000     69.000000     9.000000   104.000000     1.000000   \n",
       "50%      39.000000    444.000000    16.000000   185.000000     2.000000   \n",
       "75%      49.000000   1480.000000    21.000000   329.000000     3.000000   \n",
       "max      87.000000  71188.000000    31.000000  3025.000000    50.000000   \n",
       "\n",
       "             pdays     previous  \n",
       "count  4521.000000  4521.000000  \n",
       "mean     39.766645     0.542579  \n",
       "std     100.121124     1.693562  \n",
       "min      -1.000000     0.000000  \n",
       "25%      -1.000000     0.000000  \n",
       "50%      -1.000000     0.000000  \n",
       "75%      -1.000000     0.000000  \n",
       "max     871.000000    25.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuración visual\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "df = pd.read_csv('bank.csv', sep=';')\n",
    "\n",
    "# Ver las primeras filas\n",
    "display(df.head())\n",
    "\n",
    "# Información general del dataset\n",
    "print(\"Información general:\")\n",
    "df.info()\n",
    "\n",
    "# Estadísticas descriptivas para variables numéricas\n",
    "print(\"\\nEstadísticas descriptivas:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizar la variable objetivo : 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución de la variable objetivo\n",
    "print(\"Distribución de la variable 'y':\")\n",
    "print(df['y'].value_counts(normalize=True))  # proporciones\n",
    "\n",
    "# Gráfico de distribución\n",
    "sns.countplot(x='y', data=df)\n",
    "plt.title('Distribución de la variable objetivo (¿Contrato el depósito?)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisis de valores nulos y unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis combinado de valores nulos y unknown\n",
    "print(\"Análisis de valores nulos y unknown por columna:\")\n",
    "\n",
    "# Crear un DataFrame para el análisis\n",
    "null_analysis = pd.DataFrame({\n",
    "    'Valores_Nulos': df.isnull().sum(),\n",
    "    'Valores_Unknown': (df == 'unknown').sum(),\n",
    "    'Total_Registros': len(df)\n",
    "})\n",
    "\n",
    "# Calcular porcentajes\n",
    "null_analysis['Porcentaje_Nulos'] = (null_analysis['Valores_Nulos'] / null_analysis['Total_Registros']) * 100\n",
    "null_analysis['Porcentaje_Unknown'] = (null_analysis['Valores_Unknown'] / null_analysis['Total_Registros']) * 100\n",
    "\n",
    "# Mostrar solo las columnas que tienen valores nulos o unknown\n",
    "null_analysis = null_analysis[(null_analysis['Valores_Nulos'] > 0) | (null_analysis['Valores_Unknown'] > 0)]\n",
    "print(\"\\nResumen de valores nulos y unknown:\")\n",
    "print(null_analysis)\n",
    "\n",
    "# Visualización\n",
    "plt.figure(figsize=(12, 6))\n",
    "null_analysis[['Porcentaje_Nulos', 'Porcentaje_Unknown']].plot(kind='bar')\n",
    "plt.title('Porcentaje de Valores Nulos y Unknown por Columna')\n",
    "plt.xlabel('Columnas')\n",
    "plt.ylabel('Porcentaje')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Análisis detallado de las columnas con valores unknown\n",
    "print(\"\\nAnálisis detallado de valores 'unknown' por columna:\")\n",
    "for column in df.columns:\n",
    "    if (df[column] == 'unknown').any():\n",
    "        print(f\"\\nColumna: {column}\")\n",
    "        print(\"Distribución de valores:\")\n",
    "        print(df[column].value_counts(normalize=True).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determinar los atributos mas importantes con respecto a la clase objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Configuración visual\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "df_visualizar = pd.read_csv('bank.csv', sep=';')\n",
    "\n",
    "# Preparación de datos para el análisis\n",
    "# Convertir la variable objetivo a numérica\n",
    "le = LabelEncoder()\n",
    "df_visualizar['y'] = le.fit_transform(df_visualizar['y'])\n",
    "\n",
    "# Convertir variables categóricas a numéricas\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_columns:\n",
    "    df_visualizar[col] = le.fit_transform(df_visualizar[col])\n",
    "\n",
    "# 1. Análisis de correlación\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = df_visualizar.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Matriz de Correlación')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Análisis de importancia de características usando Random Forest\n",
    "X = df_visualizar.drop('y', axis=1)\n",
    "y = df_visualizar['y']\n",
    "\n",
    "# Entrenar un modelo Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Obtener importancia de características\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Característica': X.columns,\n",
    "    'Importancia': rf.feature_importances_\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('Importancia', ascending=False)\n",
    "\n",
    "# Visualizar importancia de características\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Importancia', y='Característica', data=feature_importance)\n",
    "plt.title('Importancia de Características (Random Forest)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar las características más importantes\n",
    "print(\"\\nTop 10 características más importantes:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertir los unknown a nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero, veamos cuántos valores 'unknown' hay antes de la limpieza\n",
    "print(\"Antes de la limpieza:\")\n",
    "print(df.isin(['unknown']).sum())\n",
    "\n",
    "# Crear una copia del DataFrame\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Reemplazar 'unknown' con NaN\n",
    "df_clean = df_clean.replace('unknown', pd.NA)\n",
    "\n",
    "# Verificar si quedaron valores 'unknown'\n",
    "print(\"\\nDespués de la limpieza:\")\n",
    "print(df_clean.isin(['unknown']).sum())\n",
    "\n",
    "# Mostrar el número de filas antes y después\n",
    "print(f\"\\nNúmero de filas antes: {len(df)}\")\n",
    "print(f\"Número de filas después: {len(df_clean)}\")\n",
    "\n",
    "# Mostrar las columnas que aún tienen valores 'unknown' si las hay\n",
    "unknown_columns = df_clean.columns[df_clean.isin(['unknown']).any()].tolist()\n",
    "if unknown_columns:\n",
    "    print(\"\\nColumnas que aún tienen valores 'unknown':\")\n",
    "    print(unknown_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis de valores nulos por columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de valores nulos por columna:\")\n",
    "for col in ['job', 'education', 'contact', 'poutcome']:\n",
    "    nulos = df_clean[col].isnull().sum()\n",
    "    porcentaje = (nulos / len(df_clean)) * 100\n",
    "    print(f\"{col}: {porcentaje:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar la columna poutcome y contact , ademas de las filas job , education "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns =['poutcome'])\n",
    "df_clean = df_clean.drop(columns =['contact'])\n",
    "\n",
    "for col in ['job' , 'education']:\n",
    "    df_clean = df_clean[df_clean[col] != 'unknown']\n",
    "\n",
    "\n",
    "\n",
    "print(\"Tamano inicial de dataset: \",df.shape[0])\n",
    "print(\"Tamano final del dataset: \",df_clean.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya ambas columnas eliminadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_clean.head())\n",
    "\n",
    "# Información general del dataset\n",
    "print(\"Información general:\")\n",
    "df_clean.info()\n",
    "\n",
    "# Estadísticas descriptivas para variables numéricas\n",
    "print(\"\\nEstadísticas descriptivas:\")\n",
    "display(df_clean.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Convertir variable objetivo a numérica\n",
    "df_clean['y'] = df_clean['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Separar características y target\n",
    "X = df_clean.drop('y', axis=1)\n",
    "y = df_clean['y']\n",
    "\n",
    "# Identificar columnas numéricas y categóricas\n",
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Preprocesamiento con ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', OneHotEncoder(drop='first'), cat_cols)\n",
    "    ])\n",
    "\n",
    "# División estratificada del dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"División completada:\")\n",
    "print(f\"  Train: {X_train.shape[0]} muestras\")\n",
    "print(f\"  Test: {X_test.shape[0]} muestras\")\n",
    "print(f\"  Positivos en train: {np.sum(y_train)} ({np.mean(y_train)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                             roc_auc_score, RocCurveDisplay, \n",
    "                             precision_recall_curve, auc,\n",
    "                             f1_score, average_precision_score)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Configuración común\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = {'AUC': 'roc_auc', 'AP': 'average_precision', 'F1': 'f1'}\n",
    "\n",
    "# Definición de modelos y parámetros\n",
    "modelos = {\n",
    "    'Árbol de Decisión': {\n",
    "        'model': DecisionTreeClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'classifier__max_depth': [3, 5, 10, None],\n",
    "            'classifier__min_samples_split': [2, 5, 10],\n",
    "            'classifier__class_weight': ['balanced']\n",
    "        }\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'classifier__n_estimators': [50, 100],\n",
    "            'classifier__max_depth': [10, 20, None],\n",
    "            'classifier__min_samples_split': [2, 5],\n",
    "            'classifier__class_weight': ['balanced']\n",
    "        }\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVC(probability=True, random_state=42),\n",
    "        'params': {\n",
    "            'classifier__C': [0.1, 1, 10],\n",
    "            'classifier__kernel': ['linear', 'rbf'],\n",
    "            'classifier__class_weight': ['balanced']\n",
    "        }\n",
    "    },\n",
    "    'Regresión Logística': {\n",
    "        'model': LogisticRegression(max_iter=1000, random_state=42),\n",
    "        'params': {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10],\n",
    "            'classifier__penalty': ['l2', None],\n",
    "            'classifier__class_weight': ['balanced']\n",
    "        }\n",
    "    },\n",
    "    'MLP Mejorado': {\n",
    "        'model': MLPClassifier(\n",
    "            max_iter=2000,\n",
    "            early_stopping=True,\n",
    "            n_iter_no_change=50,\n",
    "            validation_fraction=0.2,\n",
    "            random_state=42\n",
    "        ),\n",
    "        'params': {\n",
    "            'classifier__hidden_layer_sizes': [(150, 100), (100, 80, 50)],\n",
    "            'classifier__alpha': [0.05, 0.1],\n",
    "            'classifier__learning_rate_init': [0.01, 0.05],\n",
    "            'classifier__activation': ['relu', 'tanh'],\n",
    "            'classifier__batch_size': [64, 128],\n",
    "            'classifier__solver': ['adam'],\n",
    "            'classifier__learning_rate': ['adaptive']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Entrenamiento y evaluación\n",
    "for nombre, config in modelos.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"🔍  Entrenando: {nombre}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Crear pipeline con preprocesamiento y modelo\n",
    "    pipe = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', config['model'])\n",
    "    ])\n",
    "    \n",
    "    # Búsqueda de hiperparámetros\n",
    "    grid = GridSearchCV(\n",
    "        pipe,\n",
    "        config['params'],\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        refit='AP',  # Optimiza por Average Precision\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Entrenar sin sample_weight (especialmente para MLP)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluación\n",
    "    y_pred = grid.predict(X_test)\n",
    "    y_prob = grid.predict_proba(X_test)[:, 1] if hasattr(grid.best_estimator_, \"predict_proba\") else None\n",
    "    \n",
    "    # Métricas clave\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Manejar casos donde no hay probabilidades\n",
    "    if y_prob is not None:\n",
    "        roc_auc = roc_auc_score(y_test, y_prob)\n",
    "        avg_precision = average_precision_score(y_test, y_prob)\n",
    "    else:\n",
    "        roc_auc = None\n",
    "        avg_precision = None\n",
    "    \n",
    "    print(f\"\\n✔️ Mejores parámetros: {grid.best_params_}\")\n",
    "    \n",
    "    if roc_auc is not None:\n",
    "        print(f\"⭐ AUC-ROC: {roc_auc:.4f} | F1-score: {f1:.4f} | AP: {avg_precision:.4f}\")\n",
    "    else:\n",
    "        print(f\"⭐ F1-score: {f1:.4f}\")\n",
    "        \n",
    "    print(\"\\n📋 Reporte de clasificación:\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    \n",
    "    # Matriz de confusión\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f\"Matriz de Confusión - {nombre}\")\n",
    "    plt.xlabel(\"Predicción\")\n",
    "    plt.ylabel(\"Real\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Curva ROC (solo si hay probabilidades)\n",
    "    if y_prob is not None:\n",
    "        RocCurveDisplay.from_estimator(grid, X_test, y_test)\n",
    "        plt.title(f\"Curva ROC - {nombre}\")\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.show()\n",
    "        \n",
    "        # Curva Precision-Recall\n",
    "        precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(recall, precision, marker='.')\n",
    "        plt.title(f\"Curva Precision-Recall - {nombre}\\nAP={avg_precision:.4f}\" if avg_precision else f\"Curva Precision-Recall - {nombre}\")\n",
    "        plt.xlabel(\"Recall\")\n",
    "        plt.ylabel(\"Precision\")\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENTRENAR Y GUARDAR MODELO FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo SVM final guardado como 'modelo_svm_final.pkl'\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Cargar datos limpios\n",
    "df_clean = pd.read_csv('bank.csv', sep=';')\n",
    "df_clean = df_clean.drop(columns=['poutcome', 'contact'])\n",
    "for col in ['job', 'education']:\n",
    "    df_clean = df_clean[df_clean[col] != 'unknown']\n",
    "df_clean['y'] = df_clean['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Definir preprocesador\n",
    "cat_cols = df_clean.drop('y', axis=1).select_dtypes(include=['object']).columns\n",
    "num_cols = df_clean.drop('y', axis=1).select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', OneHotEncoder(drop='first'), cat_cols)\n",
    "    ])\n",
    "\n",
    "# Crear pipeline con mejores parámetros SVM\n",
    "best_svm = SVC(\n",
    "    C=1, \n",
    "    kernel='rbf', \n",
    "    class_weight='balanced', \n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline_final = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', best_svm)\n",
    "])\n",
    "\n",
    "# Entrenar con todos los datos\n",
    "X = df_clean.drop('y', axis=1)\n",
    "y = df_clean['y']\n",
    "pipeline_final.fit(X, y)\n",
    "\n",
    "# Guardar modelo\n",
    "joblib.dump(pipeline_final, 'modelo_svm_final.pkl')\n",
    "print(\"Modelo SVM final guardado como 'modelo_svm_final.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
