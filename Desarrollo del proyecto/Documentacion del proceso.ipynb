{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisis exploratorio de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1787</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>19</td>\n",
       "      <td>oct</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>4789</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>11</td>\n",
       "      <td>may</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>339</td>\n",
       "      <td>4</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1350</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>16</td>\n",
       "      <td>apr</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1476</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>jun</td>\n",
       "      <td>199</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital  education default  balance housing loan  \\\n",
       "0   30   unemployed  married    primary      no     1787      no   no   \n",
       "1   33     services  married  secondary      no     4789     yes  yes   \n",
       "2   35   management   single   tertiary      no     1350     yes   no   \n",
       "3   30   management  married   tertiary      no     1476     yes  yes   \n",
       "4   59  blue-collar  married  secondary      no        0     yes   no   \n",
       "\n",
       "    contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  cellular   19   oct        79         1     -1         0  unknown  no  \n",
       "1  cellular   11   may       220         1    339         4  failure  no  \n",
       "2  cellular   16   apr       185         1    330         1  failure  no  \n",
       "3   unknown    3   jun       199         4     -1         0  unknown  no  \n",
       "4   unknown    5   may       226         1     -1         0  unknown  no  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informaci√≥n general:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4521 entries, 0 to 4520\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        4521 non-null   int64 \n",
      " 1   job        4521 non-null   object\n",
      " 2   marital    4521 non-null   object\n",
      " 3   education  4521 non-null   object\n",
      " 4   default    4521 non-null   object\n",
      " 5   balance    4521 non-null   int64 \n",
      " 6   housing    4521 non-null   object\n",
      " 7   loan       4521 non-null   object\n",
      " 8   contact    4521 non-null   object\n",
      " 9   day        4521 non-null   int64 \n",
      " 10  month      4521 non-null   object\n",
      " 11  duration   4521 non-null   int64 \n",
      " 12  campaign   4521 non-null   int64 \n",
      " 13  pdays      4521 non-null   int64 \n",
      " 14  previous   4521 non-null   int64 \n",
      " 15  poutcome   4521 non-null   object\n",
      " 16  y          4521 non-null   object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 600.6+ KB\n",
      "\n",
      "Estad√≠sticas descriptivas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4521.000000</td>\n",
       "      <td>4521.000000</td>\n",
       "      <td>4521.000000</td>\n",
       "      <td>4521.000000</td>\n",
       "      <td>4521.000000</td>\n",
       "      <td>4521.000000</td>\n",
       "      <td>4521.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41.170095</td>\n",
       "      <td>1422.657819</td>\n",
       "      <td>15.915284</td>\n",
       "      <td>263.961292</td>\n",
       "      <td>2.793630</td>\n",
       "      <td>39.766645</td>\n",
       "      <td>0.542579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.576211</td>\n",
       "      <td>3009.638142</td>\n",
       "      <td>8.247667</td>\n",
       "      <td>259.856633</td>\n",
       "      <td>3.109807</td>\n",
       "      <td>100.121124</td>\n",
       "      <td>1.693562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>-3313.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>444.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>1480.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>329.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>87.000000</td>\n",
       "      <td>71188.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>3025.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age       balance          day     duration     campaign  \\\n",
       "count  4521.000000   4521.000000  4521.000000  4521.000000  4521.000000   \n",
       "mean     41.170095   1422.657819    15.915284   263.961292     2.793630   \n",
       "std      10.576211   3009.638142     8.247667   259.856633     3.109807   \n",
       "min      19.000000  -3313.000000     1.000000     4.000000     1.000000   \n",
       "25%      33.000000     69.000000     9.000000   104.000000     1.000000   \n",
       "50%      39.000000    444.000000    16.000000   185.000000     2.000000   \n",
       "75%      49.000000   1480.000000    21.000000   329.000000     3.000000   \n",
       "max      87.000000  71188.000000    31.000000  3025.000000    50.000000   \n",
       "\n",
       "             pdays     previous  \n",
       "count  4521.000000  4521.000000  \n",
       "mean     39.766645     0.542579  \n",
       "std     100.121124     1.693562  \n",
       "min      -1.000000     0.000000  \n",
       "25%      -1.000000     0.000000  \n",
       "50%      -1.000000     0.000000  \n",
       "75%      -1.000000     0.000000  \n",
       "max     871.000000    25.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuraci√≥n visual\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "df = pd.read_csv('bank.csv', sep=';')\n",
    "\n",
    "# Ver las primeras filas\n",
    "display(df.head())\n",
    "\n",
    "# Informaci√≥n general del dataset\n",
    "print(\"Informaci√≥n general:\")\n",
    "df.info()\n",
    "\n",
    "# Estad√≠sticas descriptivas para variables num√©ricas\n",
    "print(\"\\nEstad√≠sticas descriptivas:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizar la variable objetivo : 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuci√≥n de la variable objetivo\n",
    "print(\"Distribuci√≥n de la variable 'y':\")\n",
    "print(df['y'].value_counts(normalize=True))  # proporciones\n",
    "\n",
    "# Gr√°fico de distribuci√≥n\n",
    "sns.countplot(x='y', data=df)\n",
    "plt.title('Distribuci√≥n de la variable objetivo (¬øContrato el dep√≥sito?)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisis de valores nulos y unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis combinado de valores nulos y unknown\n",
    "print(\"An√°lisis de valores nulos y unknown por columna:\")\n",
    "\n",
    "# Crear un DataFrame para el an√°lisis\n",
    "null_analysis = pd.DataFrame({\n",
    "    'Valores_Nulos': df.isnull().sum(),\n",
    "    'Valores_Unknown': (df == 'unknown').sum(),\n",
    "    'Total_Registros': len(df)\n",
    "})\n",
    "\n",
    "# Calcular porcentajes\n",
    "null_analysis['Porcentaje_Nulos'] = (null_analysis['Valores_Nulos'] / null_analysis['Total_Registros']) * 100\n",
    "null_analysis['Porcentaje_Unknown'] = (null_analysis['Valores_Unknown'] / null_analysis['Total_Registros']) * 100\n",
    "\n",
    "# Mostrar solo las columnas que tienen valores nulos o unknown\n",
    "null_analysis = null_analysis[(null_analysis['Valores_Nulos'] > 0) | (null_analysis['Valores_Unknown'] > 0)]\n",
    "print(\"\\nResumen de valores nulos y unknown:\")\n",
    "print(null_analysis)\n",
    "\n",
    "# Visualizaci√≥n\n",
    "plt.figure(figsize=(12, 6))\n",
    "null_analysis[['Porcentaje_Nulos', 'Porcentaje_Unknown']].plot(kind='bar')\n",
    "plt.title('Porcentaje de Valores Nulos y Unknown por Columna')\n",
    "plt.xlabel('Columnas')\n",
    "plt.ylabel('Porcentaje')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# An√°lisis detallado de las columnas con valores unknown\n",
    "print(\"\\nAn√°lisis detallado de valores 'unknown' por columna:\")\n",
    "for column in df.columns:\n",
    "    if (df[column] == 'unknown').any():\n",
    "        print(f\"\\nColumna: {column}\")\n",
    "        print(\"Distribuci√≥n de valores:\")\n",
    "        print(df[column].value_counts(normalize=True).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determinar los atributos mas importantes con respecto a la clase objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Configuraci√≥n visual\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "df_visualizar = pd.read_csv('bank.csv', sep=';')\n",
    "\n",
    "# Preparaci√≥n de datos para el an√°lisis\n",
    "# Convertir la variable objetivo a num√©rica\n",
    "le = LabelEncoder()\n",
    "df_visualizar['y'] = le.fit_transform(df_visualizar['y'])\n",
    "\n",
    "# Convertir variables categ√≥ricas a num√©ricas\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_columns:\n",
    "    df_visualizar[col] = le.fit_transform(df_visualizar[col])\n",
    "\n",
    "# 1. An√°lisis de correlaci√≥n\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = df_visualizar.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Matriz de Correlaci√≥n')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. An√°lisis de importancia de caracter√≠sticas usando Random Forest\n",
    "X = df_visualizar.drop('y', axis=1)\n",
    "y = df_visualizar['y']\n",
    "\n",
    "# Entrenar un modelo Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Obtener importancia de caracter√≠sticas\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Caracter√≠stica': X.columns,\n",
    "    'Importancia': rf.feature_importances_\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('Importancia', ascending=False)\n",
    "\n",
    "# Visualizar importancia de caracter√≠sticas\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Importancia', y='Caracter√≠stica', data=feature_importance)\n",
    "plt.title('Importancia de Caracter√≠sticas (Random Forest)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar las caracter√≠sticas m√°s importantes\n",
    "print(\"\\nTop 10 caracter√≠sticas m√°s importantes:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertir los unknown a nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero, veamos cu√°ntos valores 'unknown' hay antes de la limpieza\n",
    "print(\"Antes de la limpieza:\")\n",
    "print(df.isin(['unknown']).sum())\n",
    "\n",
    "# Crear una copia del DataFrame\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Reemplazar 'unknown' con NaN\n",
    "df_clean = df_clean.replace('unknown', pd.NA)\n",
    "\n",
    "# Verificar si quedaron valores 'unknown'\n",
    "print(\"\\nDespu√©s de la limpieza:\")\n",
    "print(df_clean.isin(['unknown']).sum())\n",
    "\n",
    "# Mostrar el n√∫mero de filas antes y despu√©s\n",
    "print(f\"\\nN√∫mero de filas antes: {len(df)}\")\n",
    "print(f\"N√∫mero de filas despu√©s: {len(df_clean)}\")\n",
    "\n",
    "# Mostrar las columnas que a√∫n tienen valores 'unknown' si las hay\n",
    "unknown_columns = df_clean.columns[df_clean.isin(['unknown']).any()].tolist()\n",
    "if unknown_columns:\n",
    "    print(\"\\nColumnas que a√∫n tienen valores 'unknown':\")\n",
    "    print(unknown_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An√°lisis de valores nulos por columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de valores nulos por columna:\")\n",
    "for col in ['job', 'education', 'contact', 'poutcome']:\n",
    "    nulos = df_clean[col].isnull().sum()\n",
    "    porcentaje = (nulos / len(df_clean)) * 100\n",
    "    print(f\"{col}: {porcentaje:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar la columna poutcome y contact , ademas de las filas job , education "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns =['poutcome'])\n",
    "df_clean = df_clean.drop(columns =['contact'])\n",
    "\n",
    "for col in ['job' , 'education']:\n",
    "    df_clean = df_clean[df_clean[col] != 'unknown']\n",
    "\n",
    "\n",
    "\n",
    "print(\"Tamano inicial de dataset: \",df.shape[0])\n",
    "print(\"Tamano final del dataset: \",df_clean.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya ambas columnas eliminadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_clean.head())\n",
    "\n",
    "# Informaci√≥n general del dataset\n",
    "print(\"Informaci√≥n general:\")\n",
    "df_clean.info()\n",
    "\n",
    "# Estad√≠sticas descriptivas para variables num√©ricas\n",
    "print(\"\\nEstad√≠sticas descriptivas:\")\n",
    "display(df_clean.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Convertir variable objetivo a num√©rica\n",
    "df_clean['y'] = df_clean['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Separar caracter√≠sticas y target\n",
    "X = df_clean.drop('y', axis=1)\n",
    "y = df_clean['y']\n",
    "\n",
    "# Identificar columnas num√©ricas y categ√≥ricas\n",
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Preprocesamiento con ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', OneHotEncoder(drop='first'), cat_cols)\n",
    "    ])\n",
    "\n",
    "# Divisi√≥n estratificada del dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Divisi√≥n completada:\")\n",
    "print(f\"  Train: {X_train.shape[0]} muestras\")\n",
    "print(f\"  Test: {X_test.shape[0]} muestras\")\n",
    "print(f\"  Positivos en train: {np.sum(y_train)} ({np.mean(y_train)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                             roc_auc_score, RocCurveDisplay, \n",
    "                             precision_recall_curve, auc,\n",
    "                             f1_score, average_precision_score)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Configuraci√≥n com√∫n\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = {'AUC': 'roc_auc', 'AP': 'average_precision', 'F1': 'f1'}\n",
    "\n",
    "# Definici√≥n de modelos y par√°metros\n",
    "modelos = {\n",
    "    '√Årbol de Decisi√≥n': {\n",
    "        'model': DecisionTreeClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'classifier__max_depth': [3, 5, 10, None],\n",
    "            'classifier__min_samples_split': [2, 5, 10],\n",
    "            'classifier__class_weight': ['balanced']\n",
    "        }\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'classifier__n_estimators': [50, 100],\n",
    "            'classifier__max_depth': [10, 20, None],\n",
    "            'classifier__min_samples_split': [2, 5],\n",
    "            'classifier__class_weight': ['balanced']\n",
    "        }\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVC(probability=True, random_state=42),\n",
    "        'params': {\n",
    "            'classifier__C': [0.1, 1, 10],\n",
    "            'classifier__kernel': ['linear', 'rbf'],\n",
    "            'classifier__class_weight': ['balanced']\n",
    "        }\n",
    "    },\n",
    "    'Regresi√≥n Log√≠stica': {\n",
    "        'model': LogisticRegression(max_iter=1000, random_state=42),\n",
    "        'params': {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10],\n",
    "            'classifier__penalty': ['l2', None],\n",
    "            'classifier__class_weight': ['balanced']\n",
    "        }\n",
    "    },\n",
    "    'MLP Mejorado': {\n",
    "        'model': MLPClassifier(\n",
    "            max_iter=2000,\n",
    "            early_stopping=True,\n",
    "            n_iter_no_change=50,\n",
    "            validation_fraction=0.2,\n",
    "            random_state=42\n",
    "        ),\n",
    "        'params': {\n",
    "            'classifier__hidden_layer_sizes': [(150, 100), (100, 80, 50)],\n",
    "            'classifier__alpha': [0.05, 0.1],\n",
    "            'classifier__learning_rate_init': [0.01, 0.05],\n",
    "            'classifier__activation': ['relu', 'tanh'],\n",
    "            'classifier__batch_size': [64, 128],\n",
    "            'classifier__solver': ['adam'],\n",
    "            'classifier__learning_rate': ['adaptive']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Entrenamiento y evaluaci√≥n\n",
    "for nombre, config in modelos.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"üîç  Entrenando: {nombre}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Crear pipeline con preprocesamiento y modelo\n",
    "    pipe = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', config['model'])\n",
    "    ])\n",
    "    \n",
    "    # B√∫squeda de hiperpar√°metros\n",
    "    grid = GridSearchCV(\n",
    "        pipe,\n",
    "        config['params'],\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        refit='AP',  # Optimiza por Average Precision\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Entrenar sin sample_weight (especialmente para MLP)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluaci√≥n\n",
    "    y_pred = grid.predict(X_test)\n",
    "    y_prob = grid.predict_proba(X_test)[:, 1] if hasattr(grid.best_estimator_, \"predict_proba\") else None\n",
    "    \n",
    "    # M√©tricas clave\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Manejar casos donde no hay probabilidades\n",
    "    if y_prob is not None:\n",
    "        roc_auc = roc_auc_score(y_test, y_prob)\n",
    "        avg_precision = average_precision_score(y_test, y_prob)\n",
    "    else:\n",
    "        roc_auc = None\n",
    "        avg_precision = None\n",
    "    \n",
    "    print(f\"\\n‚úîÔ∏è Mejores par√°metros: {grid.best_params_}\")\n",
    "    \n",
    "    if roc_auc is not None:\n",
    "        print(f\"‚≠ê AUC-ROC: {roc_auc:.4f} | F1-score: {f1:.4f} | AP: {avg_precision:.4f}\")\n",
    "    else:\n",
    "        print(f\"‚≠ê F1-score: {f1:.4f}\")\n",
    "        \n",
    "    print(\"\\nüìã Reporte de clasificaci√≥n:\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    \n",
    "    # Matriz de confusi√≥n\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f\"Matriz de Confusi√≥n - {nombre}\")\n",
    "    plt.xlabel(\"Predicci√≥n\")\n",
    "    plt.ylabel(\"Real\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Curva ROC (solo si hay probabilidades)\n",
    "    if y_prob is not None:\n",
    "        RocCurveDisplay.from_estimator(grid, X_test, y_test)\n",
    "        plt.title(f\"Curva ROC - {nombre}\")\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.show()\n",
    "        \n",
    "        # Curva Precision-Recall\n",
    "        precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(recall, precision, marker='.')\n",
    "        plt.title(f\"Curva Precision-Recall - {nombre}\\nAP={avg_precision:.4f}\" if avg_precision else f\"Curva Precision-Recall - {nombre}\")\n",
    "        plt.xlabel(\"Recall\")\n",
    "        plt.ylabel(\"Precision\")\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENTRENAR Y GUARDAR MODELO FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo SVM final guardado como 'modelo_svm_final.pkl'\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Cargar datos limpios\n",
    "df_clean = pd.read_csv('bank.csv', sep=';')\n",
    "df_clean = df_clean.drop(columns=['poutcome', 'contact'])\n",
    "for col in ['job', 'education']:\n",
    "    df_clean = df_clean[df_clean[col] != 'unknown']\n",
    "df_clean['y'] = df_clean['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Definir preprocesador\n",
    "cat_cols = df_clean.drop('y', axis=1).select_dtypes(include=['object']).columns\n",
    "num_cols = df_clean.drop('y', axis=1).select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', OneHotEncoder(drop='first'), cat_cols)\n",
    "    ])\n",
    "\n",
    "# Crear pipeline con mejores par√°metros SVM\n",
    "best_svm = SVC(\n",
    "    C=1, \n",
    "    kernel='rbf', \n",
    "    class_weight='balanced', \n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline_final = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', best_svm)\n",
    "])\n",
    "\n",
    "# Entrenar con todos los datos\n",
    "X = df_clean.drop('y', axis=1)\n",
    "y = df_clean['y']\n",
    "pipeline_final.fit(X, y)\n",
    "\n",
    "# Guardar modelo\n",
    "joblib.dump(pipeline_final, 'modelo_svm_final.pkl')\n",
    "print(\"Modelo SVM final guardado como 'modelo_svm_final.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
